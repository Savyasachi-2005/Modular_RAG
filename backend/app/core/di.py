from functools import lru_cache
import requests
import json

from ..core.config import settings

# Prefer local lightweight implementations for embeddings and vector store.
from ..index.embeddings import EmbeddingEncoder as LocalEmbeddingEncoder
from ..index.vector_store import VectorStore
from .gemini_client import generate_with_gemini


class GeneratorClient:
    def __init__(self, provider: str):
        self.provider = provider

    def generate(self, prompt: str) -> str:
        # Use the Gemini client helper when provider is gemini and API key exists
        if self.provider and self.provider.lower() == "gemini" and settings.gemini_api_key:
            return generate_with_gemini(prompt)

        # Fallback deterministic stub
        return f"[generated by {self.provider}] {prompt[:200]}"


@lru_cache(maxsize=1)
def get_encoder() -> LocalEmbeddingEncoder:
    return LocalEmbeddingEncoder(settings.embedding_model_name, dim=768)


@lru_cache(maxsize=1)
def get_vector_store() -> VectorStore:
    return VectorStore(path=settings.faiss_index_path, dim=768)


@lru_cache(maxsize=1)
def get_generator() -> GeneratorClient:
    # If a Gemini API key is available, prefer Gemini regardless of the
    # configured generator_provider (this makes local .env-configured keys
    # take precedence so users don't need to flip the provider setting).
    provider = settings.generator_provider
    try:
        if getattr(settings, "gemini_api_key", None):
            provider = "gemini"
    except Exception:
        pass
    return GeneratorClient(provider)


